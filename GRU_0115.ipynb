{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542175a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e5fe0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know, \n",
      "Source Train: (135828, 16)\n",
      "Target Train: (135828, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import re \n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "\n",
    "raw = []\n",
    "raw_corpus = [] \n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "        \n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()  # 소문자, 양쪽공백 제거\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)  # 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "    sentence = sentence.strip()  # 양쪽 공백 제거\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    return sentence\n",
    "\n",
    "corpus = []  # 형태 : ['<start> i m begging of you please don t take my man <end>', ...] length - 175986\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    tmp = preprocess_sentence(sentence)\n",
    "    if len(tmp.split()) > 20: continue\n",
    "    corpus.append(tmp)\n",
    "\n",
    "    \n",
    "def tokenize(corpus):\n",
    "    # num_words:전체 단어의 개수, filters:별도로 전처리 로직을 추가, oov_token: out-of-vocabulary 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=12000, filters=' ', oov_token=\"<unk>\")\n",
    "    tokenizer.fit_on_texts(corpus)  # corpus로부터 Tokenizer가 사전을 자동구축\n",
    "    # tokenizer를 활용하여 모델에 입력할 데이터셋 구축(Tensor로 변환)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    # 입력 데이터 시퀀스 길이 맞춰주기 - padding\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=maxlen)\n",
    "\n",
    "    return tensor, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)\n",
    "\n",
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if len(sentence) > 15: continue\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "        \n",
    "print(sentence[:10])\n",
    "\n",
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성. 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높다.\n",
    "tgt_input = tensor[:, 1:]  # tensor에서 <start>를 잘라내서 타겟 문장을 생성 -> 문장 길이는 14가 됨\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=48)\n",
    "print(\"Source Train:\", enc_train.shape)  # (124960, 14)  # 현재 (124981, 14)\n",
    "print(\"Target Train:\", dec_train.shape)  # (124960, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb20a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6792/6792 [==============================] - 219s 29ms/step - loss: 2.6390 - val_loss: 2.3796\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Embedding,LSTM, GRU,  Dense\n",
    "\n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize = (12, 8))\n",
    "    \n",
    "    for i in range(len(ax)):\n",
    "        ax[i].set_xlabel('Epochs')\n",
    "        ax[i].set_ylabel('Value')\n",
    "        \n",
    "        for n in range(len(list_of_metrics)):\n",
    "            if i == 0:\n",
    "                y = hist[list_of_metrics[n]]\n",
    "                if n == 0:\n",
    "                    ax[i].plot(epochs, y, label=\"train\")\n",
    "                else:\n",
    "                    ax[i].plot(epochs, y, label=\"val\")\n",
    "                ax[i].set_title('Loss')\n",
    "                ax[i].legend(loc='upper right')\n",
    "                if n == 1:\n",
    "                    break\n",
    "            else:\n",
    "                if n >= 2:\n",
    "                    y = hist[list_of_metrics[n]]\n",
    "                    if n == 2:\n",
    "                        ax[i].plot(epochs, y, label=\"train\")\n",
    "                    else:\n",
    "                        ax[i].plot(epochs, y, label=\"val\")\n",
    "                    ax[i].set_title('Accuracy')\n",
    "                    ax[i].legend(loc='lower right')\n",
    "                    \n",
    "    plt.show()\n",
    "    \n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = GRU(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = GRU(hidden_size,return_sequences = True)\n",
    "        #self.rnn_3 = GRU(hidden_size, return_sequences=True)\n",
    "        #self.rnn_4 = GRU(hidden_size, return_sequences=True)\n",
    "        self.linear = Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        #out = self.rnn_3(out)\n",
    "        #out = self.rnn_4(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "history = []\n",
    "epochs = 1\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "embedding_size = 500\n",
    "hidden_size = 1000\n",
    "\n",
    "\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "history = model.fit(enc_train, \n",
    "          dec_train, \n",
    "          epochs=epochs,\n",
    "          batch_size=20,\n",
    "          validation_data=(enc_val, dec_val),\n",
    "          verbose=1)\n",
    "    \n",
    "\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "plot_curve(history.epoch, history.history, ['loss', 'val_loss'])\n",
    "\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <END>를 예측하지 않았거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86a0d16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i m a <unk> <end> '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=300):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 우리 모델이 <END>를 예측하지 않았거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다.\n",
    "\n",
    "\n",
    "generate_text(model, tokenizer, init_sentence=\"<start> I \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ca18f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> object , <unk> , <unk> , <end> '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> object \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af5d759f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> deny that , that s what i like <end> '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> deny that \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73ad5211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> so that s what i m drunk <end> '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> so that \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c0a1012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you so much <end> '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> I love \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b3c8861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you so much <end> '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> I love \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a810dd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i think that i m gonna be <end> '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> I think that \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0292053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> good night <end> '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> good \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc21ba68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> so bad , you can t be <end> '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> so bad \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a2dce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> get boy , get it get it <end> '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> get boy \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e31b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> gotta be a little selfish <end> '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> gotta \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40bb6c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> <unk> a <unk> <end> '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> I'm a \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30ed89ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> hey , hey , hey , hey , hey , hey , hey , hey , hey , hey <end> '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> hey \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e39d3d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> why you wanna trip on me <end> '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> why \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20bd33b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> out of the club <end> '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> out of  \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87fe6755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> of the <unk> <end> '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> of \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5d91e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> of the <unk> <end> '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> of the \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69263c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> she s a <unk> <end> '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> she \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b767ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> she likes to go <end> '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> she likes \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "854e756f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he likes to have a gun <end> '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> he likes \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1989d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he likes to have a gun <end> '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> He likes \", max_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a4dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
